# Proyecto Integrador de Infraestructura y Arquitectura para Big Data

Este proyecto estÃ¡ diseÃ±ado para realizar la **ingesta** de datos desde una API pÃºblica, almacenarlos en una base de datos SQLite y permitir su posterior **limpieza y anÃ¡lisis** mediante scripts automatizados en Python.

## ğŸš€ **DescripciÃ³n**

Este proyecto obtiene datos de la API [JSONPlaceholder](https://jsonplaceholder.typicode.com/posts), que es un servicio de pruebas para desarrolladores. Los datos extraÃ­dos se almacenan en una base de datos SQLite local, permitiendo su anÃ¡lisis, limpieza y manipulaciÃ³n posterior.

### ğŸ”¥ **Funcionalidades:**

âœ… Realiza una solicitud `GET` a la API para obtener datos.

âœ… Almacena los datos en una base de datos SQLite.

âœ… Evita duplicados en la base de datos mediante restricciones Ãºnicas.

âœ… Exporta los datos a formatos **CSV** y **Excel** para su anÃ¡lisis.

âœ… Limpia los datos, manejando valores nulos y datos duplicados.

âœ… Genera un informe de auditorÃ­a detallado con el estado de los datos.

---

## ğŸ“‚ **Estructura del Proyecto**

```
[bigdata-infrastructure]
â”‚   .gitattributes
â”‚   .gitignore
â”‚   mkdocs.yml
â”‚   README.md
â”‚   requirements.txt
â”‚   run.py
â”‚   setup.py
â”‚
â”œâ”€â”€â”€.github
â”‚   â””â”€â”€â”€workflows
â”‚           bigdata.yml
â”‚
â”œâ”€â”€â”€.qodo
â”‚       history.sqlite
â”‚
â”œâ”€â”€â”€bigdata_infrastructure.egg-info
â”‚       dependency_links.txt
â”‚       PKG-INFO
â”‚       requires.txt
â”‚       SOURCES.txt
â”‚       top_level.txt
â”‚
â”œâ”€â”€â”€build
â”‚   â””â”€â”€â”€bdist.win-amd64
â”œâ”€â”€â”€docs
â”‚       index.md
â”‚       ingesta.md
â”‚       limpieza.md
â”‚
â””â”€â”€â”€src
    â”‚   cleaning.py
    â”‚   ingestion.py
    â”‚
    â””â”€â”€â”€static
        â”œâ”€â”€â”€auditoria
        â”‚       cleaning_report.txt
        â”‚       ingestion_report.txt
        â”‚
        â”œâ”€â”€â”€csv
        â”‚       ingestion.csv
        â”‚
        â”œâ”€â”€â”€db
        â”‚       ingestion.db
        â”‚
        â””â”€â”€â”€xlsx
                cleaning.xlsx
                ingestion.xlsx
```

---

## ğŸ› ï¸ **Requisitos**

Para ejecutar este proyecto, necesitas tener instalados los siguientes paquetes y herramientas:

* **Python 3.x**
* **SQLite3** (ya viene incluido con Python)
* Bibliotecas adicionales de Python que puedes instalar fÃ¡cilmente usando `pip`

---

## ğŸ“¥ **InstalaciÃ³n de las dependencias**

1. Clona el repositorio desde GitHub:

```bash
git clone https://github.com/JuanesMedCol/bigdata-infrastructure.git
```

2. Accede al directorio del proyecto:

```bash
cd bigdata-infrastructure
```

3. Instala las dependencias desde el archivo `requirements.txt` o usando el setup:

```bash
Opcion 1: pip install -r requirements.txt
Opcion 2: pip install .
```

---

## ğŸš€ **EjecuciÃ³n del Proyecto**

Este script ejecuta en orden toda la rutina del programa:

```bash
python run.py
```

---

## ğŸ“Š Modelo de Base de Datos

### ğŸ§© Estructura de la tabla `posts`

La base de datos `ingestion.db` contiene la tabla `posts` donde se almacenan los datos obtenidos del API.

```sql
CREATE TABLE IF NOT EXISTS posts (
    id INTEGER PRIMARY KEY,
    title TEXT,
    body TEXT
)
```

| Campo     | Tipo    | DescripciÃ³n              |
| --------- | ------- | ------------------------- |
| `id`    | INTEGER | Identificador Ãºnico (PK) |
| `title` | TEXT    | TÃ­tulo del post          |
| `body`  | TEXT    | Contenido del post        |

---

## ğŸ§  Diagrama Mermaid â€“ Modelo de Datos

``` mermaid
erDiagram
    posts {
        INTEGER id PK
        TEXT title
        TEXT body
    }
```

---
