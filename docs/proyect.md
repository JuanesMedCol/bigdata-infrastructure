## üìò Documento de Arquitectura del Proyecto Integrador de Big Data

### 1. Introducci√≥n y Descripci√≥n Global de la Arquitectura

El proyecto integra tres fases principales en un entorno simulado de Big Data en la nube: **ingesta**, **limpieza** y **enriquecimiento** de datos. Utiliza `SQLite` como base de datos local simulando un almac√©n anal√≠tico, y `Python` como lenguaje principal para el procesamiento de datos. El flujo de trabajo se automatiza mediante `GitHub Actions` y se documenta con `MkDocs`.

---

### 2. Diagramas de Flujo y Arquitectura

**Diagrama 1: Flujo General del Proyecto**

- Desde la API p√∫blica `restcountries.com`, se extrae la informaci√≥n de pa√≠ses.
- Los datos son almacenados en SQLite (`countries`).
- Luego se realiza la limpieza y se guarda en `countries_clean`.
- Finalmente, se enriquecen con coordenadas geogr√°ficas usando la API de OpenCage y se guarda en `countries_enriched`.

**Diagrama 2: Proceso de Enriquecimiento**

- Entrada: `cleaning.xlsx` ‚Üí Proceso de geolocalizaci√≥n por capital ‚Üí Salida: `enriched_data.xlsx` y `countries_enriched`.

‚úÖ *Puedo ayudarte a generar estos diagramas con base en esta estructura si lo deseas.*

---

### 3. Explicaci√≥n Detallada de Componentes

#### üîπ Ingesta

-**Fuente**: API `https://restcountries.com/v3.1/all`

-**Herramientas**: `requests`, `pandas`, `sqlite3`

-**Salida**: `ingestion.db`, `ingestion.csv`, `ingestion.xlsx`, `ingestion_report.txt`

#### üîπ Limpieza

- Elimina duplicados y rellena nulos seg√∫n el tipo de dato.
- Guarda resultados en `cleaning.xlsx` y tabla `countries_clean`.

#### üîπ Enriquecimiento

- Uso de API `OpenCageData` para agregar latitud y longitud por capital.
- Resultado: tabla `countries_enriched` y Excel `enriched_data.xlsx`.

---

### 4. Modelo de Datos

**Tablas:**

-`countries`: datos en crudo.

-`countries_clean`: despu√©s de limpieza.

-`countries_enriched`: con latitud y longitud.

**Relaciones:**

- Todas las tablas comparten el campo clave `pais`.

‚úÖ *Te puedo generar un diagrama ER (Entidad-Relaci√≥n) que muestre esta evoluci√≥n de los datos.*

---

### 5. Justificaci√≥n de Herramientas

-**SQLite**: ligero, ideal para simulaci√≥n local y consultas anal√≠ticas.

-**Pandas**: procesamiento flexible y potente de datos.

-**Requests**: extracci√≥n directa desde APIs REST.

-**GitHub Actions**: permite automatizaci√≥n continua del flujo ETL.

-**MkDocs**: ideal para documentaci√≥n estructurada del proyecto.

---

### 6. Simulaci√≥n del Entorno en la Nube

Aunque no se ejecuta en una nube real como AWS o GCP, el entorno simulado replica sus fases:

- Almacenamiento en SQLite como si fuera un almac√©n anal√≠tico.
- Automatizaci√≥n y despliegue mediante GitHub Actions.
- Visualizaci√≥n estructurada con MkDocs como portal web de documentaci√≥n.

---

### 7. Flujo de Datos y Automatizaci√≥n

Desde `main.py` o `run.py`, puede ejecutarse el pipeline completo:

1.`ingestion.py` ‚Üí genera `countries`

2.`cleaning.py` ‚Üí transforma en `countries_clean`

3.`enrichment.py` ‚Üí finaliza en `countries_enriched`

Cada script genera reportes de auditor√≠a para trazabilidad.

---

### 8. Conclusiones y Recomendaciones

**Beneficios:**

- Flujo estructurado y automatizado.
- Datos enriquecidos para an√°lisis geogr√°fico.
- Documentaci√≥n reproducible y clara.

**Limitaciones:**

- No hay paralelizaci√≥n ni procesamiento distribuido (sin Spark en producci√≥n).
- Simulaci√≥n local, no cloud-native real.

**Recomendaciones:**

- Implementar el mismo flujo en AWS con S3 + Glue + Athena.
- Agregar validaciones m√°s complejas.
- Considerar Spark para procesamiento a gran escala.
